{"cells":[{"cell_type":"markdown","source":["<h2>INTRODUCTION TO PARTITION</h2>\n\nSpark is one of the distributed computing platform that split data into partitions to achieve parallel computation. The challange with these distributed computing platforms is to manage these partition to keep your spark computations running efficiently. In this topic we discuss how to manage the spark partition with repartition and coalesce."],"metadata":{}},{"cell_type":"code","source":["#Let's create a dataframe to illustrate how data is partitioned.\nds = spark.range(1, 11)\nds = ds.withColumnRenamed(\"id\", \"num_idb\")\ndisplay(ds)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["\"\"\"\nCheck the number of parition\n\"\"\"\n\nds.rdd.getNumPartitions()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["\"\"\"\nGet the parition distribution\n\"\"\"\nfrom pyspark.sql.functions import spark_partition_id\n\nds.select(*ds.columns, spark_partition_id().alias(\"pid\")).show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["<h2>coalesce</h2>\nThe coalesce method reduces the number of partitions in a DataFrame. Here’s how to consolidate the data in two partitions:"],"metadata":{}},{"cell_type":"code","source":["\"\"\"\nUse colaesce function to reduce the number of parition.In this case we are reducing to 2 partition.\nAnd also verifying the partition distribution after the coalesce.\n\"\"\"\ndsCoalesce = ds.coalesce(2)\ndsCoalesce.rdd.getNumPartitions()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from pyspark.sql.functions import spark_partition_id\ndsCoalesce.select(*dsCoalesce.columns, spark_partition_id().alias(\"pid\")).show()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["<h2>Increasing partitions using coalesce</h2>\nYou can try to increase the number of partitions with coalesce, but it won’t work!"],"metadata":{}},{"cell_type":"code","source":["\"\"\"\nUse colaesce function to increase the number of parition and see it won't effect the partitions.\n\"\"\"\nfrom pyspark.sql.functions import spark_partition_id\n\ndsCoalesceInc = ds.coalesce(10)\n\ndsCoalesceInc.rdd.getNumPartitions()\n\n#dsCoalesceInc.select(*dsCoalesceInc.columns, spark_partition_id().alias(\"pid\")).show()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["<h2>Repartition</h2>\nThe repartition method can be used to either increase or decrease the number of partitions in a DataFrame."],"metadata":{}},{"cell_type":"code","source":["\"\"\"\nLet's create with repartition on ds dataframe\n\"\"\"\ndsRepartition = ds.repartition(2)\ndsRepartition.rdd.getNumPartitions()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["from pyspark.sql.functions import spark_partition_id\ndsRepartition.select(*dsRepartition.columns, spark_partition_id().alias(\"pid\")).show()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["<h2>Increasing partitions using repartition</h2>\nRepartition will be used to increase the number of partition."],"metadata":{}},{"cell_type":"code","source":["\"\"\"\nIncrease the partition size.\n\"\"\"\ndsRepartitionInc = ds.repartition(10)\ndsRepartitionInc.rdd.getNumPartitions()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.sql.functions import spark_partition_id\ndsRepartitionInc.select(*dsRepartitionInc.columns, spark_partition_id().alias(\"pid\")).show()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["\"\"\"\nThe above results showing only the assigned partition number but not include any empty parition in the results.\nIf you need the entire structure of the partition that includes the empty partitions use the below code.\n\"\"\"\nprint('Partitions structure: {}'.format(dsRepartitionInc.rdd.glom().collect()))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["<h2>Differences between coalesce and repartition</h2>\nThe repartition algorithm does a full shuffle of the data and creates equal sized partitions of data. coalesce combines existing partitions to avoid a full shuffle."],"metadata":{}}],"metadata":{"name":"10-Partitioning-Performance","notebookId":3923461933236601},"nbformat":4,"nbformat_minor":0}
